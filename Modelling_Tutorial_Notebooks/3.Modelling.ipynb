{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a09f0e4f-78c4-4c26-816a-50d6c8bf6917",
   "metadata": {},
   "source": [
    "### Intro"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be7e8d86-fcfa-4ec0-b92b-e78461e77bcb",
   "metadata": {},
   "source": [
    "In this notebook, we will model the light curves using the trained model from the previous notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21a4bada-a7c2-4c9f-9745-9aeddd3a06f9",
   "metadata": {},
   "source": [
    "### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c3b96cd-afe2-4359-a593-17967a14783f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\anaconda3\\envs\\QNPy\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import PREDICTION as por #Importing PREDICTION_onePDF module from the package\n",
    "from PREDICTION import * #Importing importing all packages from PREDICTION_onePDF module\n",
    "#The functions plot_function2, back_x and back_y must be imported separately\n",
    "from PREDICTION import plot_function2, back_x, back_y, find_LC_transform "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32d82604-f641-48ef-bc13-40d259306691",
   "metadata": {},
   "source": [
    "### Model Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eca40e7f-70cb-47ee-99f5-24ba9095d6ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model hyperparameters\n",
    "encoding_size = 128 #Encoder MLP layer size\n",
    "latent_size = 128 #Latent dimension size\n",
    "no_latent_samples = 10 #The number of samples of the latent space to take\n",
    "\n",
    "attention_type = 'scaledot' #Can also use multihead, but scaledot works better\n",
    "cross_attention = True #Whether to include cross-attention in the deterministic path\n",
    "self_attention = True #Whether to include self-attention in both paths\n",
    "\n",
    "lstm_layers = 0 #The number of LSTM layers to use for pre-encoding\n",
    "lstm_size = 32 #The size of the LSTM layer\n",
    "\n",
    "replace_lstm_with_gru = False # Whether to use a GRU instead of an LSTM\n",
    "bidirectional = False #Whether to use bidirectional LSTM/GRU layers\n",
    "lstm_agg = False #Whether to aggregate the latent space representations via an LSTM instead of mean pooling\n",
    "activation = 'relu' #Can also make it 'leaky' for LeakyReLu but ReLu seems to work better\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") #defining the device for testing, it can be CPU or CUDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd53f1a9-bb0e-43f9-a59d-f3aa964c660e",
   "metadata": {},
   "source": [
    "### TF and Param Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3246923c-3fc8-4fbf-8046-c990d6132a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The paths for the transfer function and parameters if they exist\n",
    "tf_and_param = False #Set false if using real data without transfer function and parameter\n",
    "if tf_and_param:\n",
    "    TF_PATH = f'Transfer_Functions/'\n",
    "    param_df_path = 'Parameters.csv' #If there is no parameters dataframe, it should be None\n",
    "    parameters_df = pd.read_csv(param_df_path)\n",
    "    param_columns=['Log_Mass','Inclination','Log_Tau','z','Eddington_Ratio','SFinf'] #Change to the names of your columns\n",
    "    param_length = len(param_columns)\n",
    "    TF_SAVE_PATH_TRAIN = f'{full_folder}/output_{suffix}/predictions/Transfer_Functions/train/'\n",
    "    TF_SAVE_PATH_TEST = f'{full_folder}/output_{suffix}/predictions/Transfer_Functions/test/'\n",
    "    TF_SAVE_PATH_VAL = f'{full_folder}/output_{suffix}/predictions/Transfer_Functions/val/'\n",
    "    PARAM_SAVE_PATH_TRAIN = f'{full_folder}/output_{suffix}/predictions/Parameter_Predictions/train/'\n",
    "    PARAM_SAVE_PATH_VAL = f'{full_folder}/output_{suffix}/predictions/Parameter_Predictions/val/'\n",
    "    PARAM_SAVE_PATH_TEST = f'{full_folder}/output_{suffix}/predictions/Parameter_Predictions/test/'\n",
    "    beta_param = 0.1 #Change to the value you trained\n",
    "    beta_tf = 0.1 #Change to the value you trained\n",
    "    transfer_function_length = 1000 #Change to the appropriate tf_length\n",
    "else:\n",
    "    TF_PATH = None\n",
    "    param_df = None\n",
    "    param_columns = []\n",
    "    param_length = 0\n",
    "    beta_param = 0\n",
    "    beta_tf = 0\n",
    "    transfer_function_length = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc3861c2-47d3-4463-a48c-5df1b54e3943",
   "metadata": {},
   "source": [
    "### Creating Folders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec8948ad-d8c7-4aaf-8dc0-cd4084b333e5",
   "metadata": {},
   "source": [
    "We remove the padding from the curves. Thus, if you would like to train the model more, please save a copy of the dataset folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "14ada347-7780-45ac-8169-759ef56acb77",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The folder that all the files are in\n",
    "full_folder = './'\n",
    "suffix = f'LCs' #Whatever suffix you gave to the output files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "894a3850-0242-4c09-937f-d3582243490e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder already exists: .//output_LCs/predictions\\train\n",
      "Folder already exists: .//output_LCs/predictions\\train\\plots\n",
      "Folder already exists: .//output_LCs/predictions\\train\\data\n",
      "Folder already exists: .//output_LCs/predictions\\test\n",
      "Folder already exists: .//output_LCs/predictions\\test\\plots\n",
      "Folder already exists: .//output_LCs/predictions\\test\\data\n",
      "Folder already exists: .//output_LCs/predictions\\val\n",
      "Folder already exists: .//output_LCs/predictions\\val\\plots\n",
      "Folder already exists: .//output_LCs/predictions\\val\\data\n"
     ]
    }
   ],
   "source": [
    "#Creating the predictions folder\n",
    "os.makedirs(f'{full_folder}/output_{suffix}/predictions',exist_ok=True)\n",
    "os.makedirs(f'{full_folder}/output_{suffix}/predictions/Transfer_Functions/test',exist_ok=True)\n",
    "os.makedirs(f'{full_folder}/output_{suffix}/predictions/Transfer_Functions/train',exist_ok=True)\n",
    "os.makedirs(f'{full_folder}/output_{suffix}/predictions/Transfer_Functions/val',exist_ok=True)\n",
    "os.makedirs(f'{full_folder}/output_{suffix}/predictions/Parameter_Predictions/test',exist_ok=True)\n",
    "os.makedirs(f'{full_folder}/output_{suffix}/predictions/Parameter_Predictions/train',exist_ok=True)\n",
    "os.makedirs(f'{full_folder}/output_{suffix}/predictions/Parameter_Predictions/val',exist_ok=True)\n",
    "por.create_prediction_folders(f'{full_folder}/output_{suffix}/predictions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "88f0a5ba-061d-4ff5-bdec-feedf1a0494c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed padding in file: 35_split49.csv\n",
      "Removed padding in file: 58_split41.csv\n",
      "Removed padding in file: 5_split96.csv\n",
      "Removed padding in file: 60_split75.csv\n",
      "Removed padding in file: 11_split48.csv\n",
      "Removed padding in file: 14_split32.csv\n",
      "Removed padding in file: 15_split6.csv\n",
      "Removed padding in file: 16_split65.csv\n",
      "Removed padding in file: 17_split26.csv\n",
      "Removed padding in file: 18_split83.csv\n",
      "Removed padding in file: 1_split82.csv\n",
      "Removed padding in file: 20_split36.csv\n",
      "Removed padding in file: 21_split16.csv\n",
      "Removed padding in file: 22_split21.csv\n",
      "Removed padding in file: 23_split88.csv\n",
      "Removed padding in file: 24_split10.csv\n",
      "Removed padding in file: 25_split5.csv\n",
      "Removed padding in file: 27_split78.csv\n",
      "Removed padding in file: 28_split67.csv\n",
      "Removed padding in file: 29_split24.csv\n",
      "Removed padding in file: 2_split46.csv\n",
      "Removed padding in file: 30_split80.csv\n",
      "Removed padding in file: 32_split47.csv\n",
      "Removed padding in file: 34_split76.csv\n",
      "Removed padding in file: 36_split99.csv\n",
      "Removed padding in file: 37_split59.csv\n",
      "Removed padding in file: 38_split27.csv\n",
      "Removed padding in file: 39_split64.csv\n",
      "Removed padding in file: 3_split9.csv\n",
      "Removed padding in file: 40_split57.csv\n",
      "Removed padding in file: 41_split94.csv\n",
      "Removed padding in file: 42_split35.csv\n",
      "Removed padding in file: 43_split56.csv\n",
      "Removed padding in file: 44_split87.csv\n",
      "Removed padding in file: 45_split44.csv\n",
      "Removed padding in file: 46_split37.csv\n",
      "Removed padding in file: 47_split79.csv\n",
      "Removed padding in file: 49_split17.csv\n",
      "Removed padding in file: 4_split18.csv\n",
      "Removed padding in file: 50_split31.csv\n",
      "Removed padding in file: 51_split39.csv\n",
      "Removed padding in file: 52_split74.csv\n",
      "Removed padding in file: 53_split86.csv\n",
      "Removed padding in file: 54_split29.csv\n",
      "Removed padding in file: 55_split70.csv\n",
      "Removed padding in file: 56_split20.csv\n",
      "Removed padding in file: 57_split85.csv\n",
      "Removed padding in file: 59_split30.csv\n",
      "Removed padding in file: 61_split58.csv\n",
      "Removed padding in file: 62_split52.csv\n",
      "Removed padding in file: 63_split28.csv\n",
      "Removed padding in file: 64_split97.csv\n",
      "Removed padding in file: 65_split7.csv\n",
      "Removed padding in file: 66_split51.csv\n",
      "Removed padding in file: 67_split61.csv\n",
      "Removed padding in file: 69_split45.csv\n",
      "Removed padding in file: 6_split60.csv\n",
      "Removed padding in file: 70_split43.csv\n",
      "Removed padding in file: 71_split19.csv\n",
      "Removed padding in file: 73_split13.csv\n",
      "Removed padding in file: 74_split73.csv\n",
      "Removed padding in file: 75_split69.csv\n",
      "Removed padding in file: 76_split55.csv\n",
      "Removed padding in file: 78_split81.csv\n",
      "Removed padding in file: 79_split22.csv\n",
      "Removed padding in file: 80_split89.csv\n",
      "Removed padding in file: 81_split15.csv\n",
      "Removed padding in file: 82_split90.csv\n",
      "Removed padding in file: 83_split54.csv\n",
      "Removed padding in file: 85_split11.csv\n",
      "Removed padding in file: 86_split72.csv\n",
      "Removed padding in file: 87_split93.csv\n",
      "Removed padding in file: 88_split4.csv\n",
      "Removed padding in file: 89_split3.csv\n",
      "Removed padding in file: 8_split95.csv\n",
      "Removed padding in file: 90_split62.csv\n",
      "Removed padding in file: 91_split66.csv\n",
      "Removed padding in file: 92_split34.csv\n",
      "Removed padding in file: 93_split12.csv\n",
      "Removed padding in file: 94_split14.csv\n",
      "Removed padding in file: 95_split63.csv\n",
      "Removed padding in file: 98_split33.csv\n",
      "Removed padding in file: 9_split25.csv\n",
      "Removed padding in file: 100_split53.csv\n",
      "Removed padding in file: 10_split8.csv\n",
      "Removed padding in file: 12_split71.csv\n",
      "Removed padding in file: 13_split68.csv\n",
      "Removed padding in file: 19_split1.csv\n",
      "Removed padding in file: 26_split50.csv\n",
      "Removed padding in file: 31_split40.csv\n",
      "Removed padding in file: 33_split0.csv\n",
      "Removed padding in file: 48_split23.csv\n",
      "Removed padding in file: 68_split42.csv\n",
      "Removed padding in file: 72_split38.csv\n",
      "Removed padding in file: 77_split91.csv\n",
      "Removed padding in file: 7_split2.csv\n",
      "Removed padding in file: 84_split84.csv\n",
      "Removed padding in file: 96_split92.csv\n",
      "Removed padding in file: 97_split98.csv\n",
      "Removed padding in file: 99_split77.csv\n"
     ]
    }
   ],
   "source": [
    "#deleting the padded values from test set\n",
    "folder_path = f'{full_folder}/dataset_{suffix}/test/'\n",
    "por.remove_padded_values_and_filter(folder_path)\n",
    "\n",
    "folder_path = f'{full_folder}/dataset_{suffix}/train/' \n",
    "por.remove_padded_values_and_filter(folder_path)\n",
    "\n",
    "folder_path = f'{full_folder}/dataset_{suffix}/val/'  \n",
    "por.remove_padded_values_and_filter(folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f5c6953d-8b15-4323-a688-97982d65b065",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = f\"{full_folder}/output_{suffix}/model_{suffix}.pth\" #path to saved model\n",
    "#Path to the data\n",
    "DATA_PATH_TRAIN = f\"{full_folder}/dataset_{suffix}/train\"\n",
    "DATA_PATH_VAL = f\"{full_folder}/dataset_{suffix}/val\"\n",
    "DATA_PATH_TEST= f\"{full_folder}/dataset_{suffix}/test\"\n",
    "OUTPUT_PATH = f'{full_folder}/output_{suffix}/predictions/' #path where to save the plots and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d9d7ad1a-90d4-423f-9676-46cc71d7f9ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clearing outputh dir if you want. Uncomment the next line\n",
    "#clear_output_dir=por.prepare_output_dir(OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e804fc52-239d-43a7-976f-751ba4c4c33f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the saved model\n",
    "model = por.load_trained_model(MODEL_PATH, device, encoding_size,latent_size,latent_mlp_size=encoding_size,attention = cross_attention,self_attention=self_attention,no_latent_space_sample=no_latent_samples,lstm_layers = lstm_layers,lstm_agg = lstm_agg,lstm_size=lstm_size,transfer_function_length=transfer_function_length,parameters_length = param_length,classes = 0,replace_lstm_with_gru=replace_lstm_with_gru\n",
    "                                ,activation=activation,bidirectional=bidirectional)\n",
    "#loading criterion and metrics\n",
    "criterion, mseMetric=por.get_criteria()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b68260d8-b9cb-4276-9004-f5f83b2c57de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading the coeffitients to transform back from [-2,2] to the real values\n",
    "tr=por.load_trcoeff(f'{full_folder}/TR_Coeffs/trcoeff_{suffix}.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "88f0cf5f-0f78-4174-a516-c107bc325a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The number of target points you want to model\n",
    "num_target_smooth = 100\n",
    "#Load train data\n",
    "trainLoader=por.load_train_data(DATA_PATH_TRAIN,num_target_smooth=num_target_smooth,tf_dir = TF_PATH,param_df=param_df,param_columns=param_columns,class_labels_df = None)\n",
    "#Load test data\n",
    "testLoader=por.load_test_data(DATA_PATH_TEST,num_target_smooth=num_target_smooth,tf_dir = TF_PATH,param_df=param_df,param_columns=param_columns,class_labels_df = None)\n",
    "#Load val data\n",
    "valLoader=por.load_val_data(DATA_PATH_VAL,num_target_smooth=num_target_smooth,tf_dir = TF_PATH,param_df=param_df,param_columns=param_columns,class_labels_df = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c551a060-6a3f-4cd0-8b31-92590ed77453",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining empty lists to store predictions\n",
    "names = []\n",
    "all_z = []\n",
    "all_R = []\n",
    "all_full_rep = []\n",
    "all_predicted_tfs = []\n",
    "all_predicted_params = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38fcdf1a-b44d-4c14-b6c3-ca9aac981c9d",
   "metadata": {},
   "source": [
    "## Reconstruction "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d53871f-19d3-46c6-b4cf-d3b49205111f",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "346841f4-43c0-4e12-80e3-db34ee68b5e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the names of the light curves and the transfer_function and params\n",
    "transfer_functions_test = []\n",
    "params_test = []\n",
    "for i in testLoader:\n",
    "    names.append(i['lcName'][0].split('_')[0])\n",
    "    if tf_and_param:\n",
    "        transfer_functions_test.append(i['transfer_function'][0].numpy())\n",
    "        params_test.append(i['parameters'][0].numpy())\n",
    "params_test = np.array(params_test)\n",
    "transfer_functions_test = np.array(transfer_functions_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c4baa6a6-9d33-4b2b-8d5a-bbd851dac0aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:04<00:00,  1.02s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#prediction and ploting of test data\n",
    "testMetrics,z_test,R_test, agg_R_z_test,predicted_params_test,predicted_tf_test,predicted_classes =por.plot_test_data(model, testLoader, criterion, mseMetric, plot_function2, device, tr,OUTPUT_PATH,beta_param = beta_param,beta_classifier=0,beta_tf=beta_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "18535276-7290-4205-b17d-c21ee90876d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save all the results to arrays\n",
    "all_z.append(z_test)\n",
    "all_R.append(R_test)\n",
    "all_full_rep.append(agg_R_z_test)\n",
    "all_predicted_tfs.append(predicted_tf_test)\n",
    "all_predicted_params.append(predicted_params_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2d79291c-c622-4e98-8974-ef7a217bcac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving test metrics\n",
    "savetest=por.save_test_metrics(OUTPUT_PATH, testMetrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d01c598-8a9c-49f1-884f-eb942a848ad6",
   "metadata": {},
   "source": [
    "#### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "15f4907f-fd0e-4d2d-b0a2-5465d6ee5496",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the names of the light curves and the transfer_function and params\n",
    "transfer_functions_train = []\n",
    "params_train = []\n",
    "for i in trainLoader:\n",
    "    names.append(i['lcName'][0].split('_')[0])\n",
    "    if tf_and_param:\n",
    "        transfer_functions_train.append(i['transfer_function'][0].numpy())\n",
    "        params_train.append(i['parameters'][0].numpy())\n",
    "params_train = np.array(params_train)\n",
    "transfer_functions_train = np.array(transfer_functions_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "aacfee03-f98c-44c3-b668-63e8c4862162",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 79/79 [00:23<00:00,  3.34it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#prediction and ploting of train data\n",
    "trainMetrics,z_train,R_train,agg_R_z_train,predicted_params_train,predicted_tf_train,predicted_classes =por.plot_train_light_curves(model, trainLoader,criterion, mseMetric, plot_function2, device,tr,OUTPUT_PATH,beta_param = beta_param,beta_classifier=0,beta_tf=beta_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "41a30793-2178-4dbe-8a81-2c011ae6a557",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save all the results to arrays\n",
    "all_z.append(z_train)\n",
    "all_R.append(R_train)\n",
    "all_full_rep.append(agg_R_z_train)\n",
    "all_predicted_tfs.append(predicted_tf_train)\n",
    "all_predicted_params.append(predicted_params_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "23301d0f-4045-439f-b125-c65d67f9b92b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the train metrics\n",
    "savetrain=por.save_train_metrics(OUTPUT_PATH, trainMetrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "509ce1e7-1e7a-4e5a-a4a1-17dea621d688",
   "metadata": {},
   "source": [
    "#### Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "61b932b7-100b-4364-9d41-16e2b5b89b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the names of the light curves and the transfer_function and params\n",
    "transfer_functions_val = []\n",
    "params_val = []\n",
    "for i in valLoader:\n",
    "    names.append(i['lcName'][0].split('_')[0])\n",
    "    if tf_and_param:\n",
    "        transfer_functions_val.append(i['transfer_function'][0].numpy())\n",
    "        params_val.append(i['parameters'][0].numpy())\n",
    "params_val = np.array(params_val)\n",
    "transfer_functions_val = np.array(transfer_functions_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7c0131bd-2f42-418c-95da-d5b023a70343",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 17/17 [00:05<00:00,  3.32it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Prediction and plotting of val data\n",
    "valMetrics,z_val,R_val,agg_R_z_val,predicted_params_val,predicted_tf_val,predicted_classes =por.plot_val_curves(model, valLoader,criterion, mseMetric, plot_function2, device,tr,OUTPUT_PATH,beta_param = beta_param,beta_classifier=0,beta_tf=beta_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "bf830eac-c5dc-4b95-b4d1-8c8bf964a28f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save all the results to arrays\n",
    "all_z.append(z_val)\n",
    "all_R.append(R_val)\n",
    "all_full_rep.append(agg_R_z_val)\n",
    "all_predicted_tfs.append(predicted_tf_val)\n",
    "all_predicted_params.append(predicted_params_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6a6e12c1-a969-4199-8a88-4c3f4076e6cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save all the hidden representations and names\n",
    "with open(f'{suffix}_Rs.pickle', 'wb') as handle:\n",
    "    pickle.dump(all_R, handle)\n",
    "    \n",
    "with open(f'{suffix}_zs.pickle', 'wb') as handle:\n",
    "    pickle.dump(all_z, handle)\n",
    "    \n",
    "with open(f'{suffix}_full_reps.pickle', 'wb') as handle:\n",
    "    pickle.dump(all_full_rep, handle)\n",
    "    \n",
    "with open(f'{suffix}_names.pickle', 'wb') as handle:\n",
    "    pickle.dump(names, handle)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "QNPy",
   "language": "python",
   "name": "qnpy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
